{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDbJWoO1yO8e"
   },
   "source": [
    "# Image Classification with CNN - LeNet5 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzQxqD6HyO8i"
   },
   "source": [
    "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFyVotRvyO8j"
   },
   "source": [
    "We will first download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTHLyL1fyO8j",
    "outputId": "125157c2-ed0f-41d7-e96b-21b5dbd88b02",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "26435584/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "4431872/4422102 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# # # If your computer is slow, try to use a subset of data, e.g.\n",
    "# X_train = X_train[:10000]\n",
    "# y_train = y_train[:10000]\n",
    "# X_test = X_test[:2000]\n",
    "# y_test = y_test[:2000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8ShXIANyO8l"
   },
   "source": [
    "As you already know, this dataset contains 10 classes:\n",
    "* 0:\tT-shirt/top\n",
    "* 1:\tTrouser\n",
    "* 2:\tPullover\n",
    "* 3:\tDress\n",
    "* 4:\tCoat\n",
    "* 5:\tSandal\n",
    "* 6:\tShirt\n",
    "* 7:\tSneaker\n",
    "* 8:\tBag\n",
    "* 9:\tAnkle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BvNG0PbyO8l"
   },
   "source": [
    "You can have a look at some images if needed, even if you already know them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "lnjqgv-GyO8m",
    "outputId": "e593f73d-ec2c-4c27-8b9d-78945bff27ed",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Explore the data, display some input images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "idx = np.random.randint(X_train.shape[0])\n",
    "\n",
    "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
    "plt.title(label_class[y_train[idx]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdYH6XW1yO8n"
   },
   "source": [
    "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjv8XMPByO8o",
    "outputId": "cf900956-5739-4717-e05b-0f0a607e12a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Make the data preparation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "X_train_norm = X_train/255# noramalise to between 0-1 *1\n",
    "X_test_norm = X_test/255\n",
    "\n",
    "\n",
    "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
    "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train_norm.shape #Should be (60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9LKzxR9yO8o"
   },
   "source": [
    "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
    "\n",
    "The architecture is the following:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKyMFlL6yO8o",
    "outputId": "69310af5-ad2c-425c-db42-7e516bf9705e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
      "                                                                 \n",
      " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
      "                                                                 \n",
      " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " C5 (Dense)                  (None, 120)               48120     \n",
      "                                                                 \n",
      " F6 (Dense)                  (None, 84)                10164     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build your model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def lenet5():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer C1\n",
    "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1))) # Similiar to sima function -- TO DO:- read uo on this\n",
    "    # Layer S2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
    "    # Layer C3\n",
    "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
    "    # Layer S4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
    "    # Before going into layer C5, we flatten our units\n",
    "    model.add(Flatten())\n",
    "    # Layer C5\n",
    "    model.add(Dense(120, activation='relu',name='C5')) #(Dense(filters=120, name='C3',activation='relu'))\n",
    "    # Layer F6\n",
    "    model.add(Dense(84, activation='relu',name='F6')) #(Dense(filters=84, name='F6',activation='relu'))\n",
    "    # Output layer\n",
    "    model.add(Dense(units=10, activation = 'softmax')) # 10 -- one for each catergory\n",
    "    \n",
    "    return model\n",
    "\n",
    "lenet5().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1qBEauqyO8p"
   },
   "source": [
    "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPL3aKnyyO8p",
    "outputId": "0424a519-d31e-4d62-9670-6270c2e3a54b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 15s 47ms/step - loss: 1.5882 - accuracy: 0.5045 - val_loss: 0.8764 - val_accuracy: 0.6726\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.7365 - accuracy: 0.7303 - val_loss: 0.6624 - val_accuracy: 0.7542\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.6022 - accuracy: 0.7723 - val_loss: 0.6020 - val_accuracy: 0.7713\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5421 - accuracy: 0.7977 - val_loss: 0.5339 - val_accuracy: 0.8016\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5054 - accuracy: 0.8139 - val_loss: 0.5050 - val_accuracy: 0.8134\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4767 - accuracy: 0.8263 - val_loss: 0.4852 - val_accuracy: 0.8250\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4591 - accuracy: 0.8338 - val_loss: 0.4636 - val_accuracy: 0.8317\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.4395 - accuracy: 0.8428 - val_loss: 0.4581 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.4263 - accuracy: 0.8468 - val_loss: 0.4510 - val_accuracy: 0.8340\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.4175 - accuracy: 0.8503 - val_loss: 0.4359 - val_accuracy: 0.8420\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4117 - accuracy: 0.8505 - val_loss: 0.4295 - val_accuracy: 0.8437\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4026 - accuracy: 0.8545 - val_loss: 0.4265 - val_accuracy: 0.8421\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3940 - accuracy: 0.8588 - val_loss: 0.4118 - val_accuracy: 0.8516\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3854 - accuracy: 0.8614 - val_loss: 0.4101 - val_accuracy: 0.8526\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3771 - accuracy: 0.8647 - val_loss: 0.4129 - val_accuracy: 0.8505\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3722 - accuracy: 0.8657 - val_loss: 0.3934 - val_accuracy: 0.8572\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3667 - accuracy: 0.8682 - val_loss: 0.3902 - val_accuracy: 0.8599\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3596 - accuracy: 0.8708 - val_loss: 0.3903 - val_accuracy: 0.8574\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3617 - accuracy: 0.8690 - val_loss: 0.3871 - val_accuracy: 0.8577\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3513 - accuracy: 0.8733 - val_loss: 0.3828 - val_accuracy: 0.8601\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3482 - accuracy: 0.8741 - val_loss: 0.3793 - val_accuracy: 0.8627\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3433 - accuracy: 0.8753 - val_loss: 0.3751 - val_accuracy: 0.8648\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3377 - accuracy: 0.8769 - val_loss: 0.3670 - val_accuracy: 0.8669\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3357 - accuracy: 0.8779 - val_loss: 0.3683 - val_accuracy: 0.8666\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3304 - accuracy: 0.8803 - val_loss: 0.3691 - val_accuracy: 0.8664\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3291 - accuracy: 0.8804 - val_loss: 0.3556 - val_accuracy: 0.8722\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3239 - accuracy: 0.8821 - val_loss: 0.3603 - val_accuracy: 0.8688\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3231 - accuracy: 0.8814 - val_loss: 0.3524 - val_accuracy: 0.8700\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3172 - accuracy: 0.8839 - val_loss: 0.3575 - val_accuracy: 0.8697\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3145 - accuracy: 0.8854 - val_loss: 0.3522 - val_accuracy: 0.8708\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3150 - accuracy: 0.8850 - val_loss: 0.3514 - val_accuracy: 0.8699\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3081 - accuracy: 0.8874 - val_loss: 0.3446 - val_accuracy: 0.8768\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3043 - accuracy: 0.8885 - val_loss: 0.3500 - val_accuracy: 0.8711\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3053 - accuracy: 0.8882 - val_loss: 0.3399 - val_accuracy: 0.8774\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2972 - accuracy: 0.8920 - val_loss: 0.3398 - val_accuracy: 0.8768\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2961 - accuracy: 0.8918 - val_loss: 0.3463 - val_accuracy: 0.8735\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2969 - accuracy: 0.8915 - val_loss: 0.3339 - val_accuracy: 0.8786\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2926 - accuracy: 0.8944 - val_loss: 0.3543 - val_accuracy: 0.8717\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2928 - accuracy: 0.8933 - val_loss: 0.3399 - val_accuracy: 0.8751\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2922 - accuracy: 0.8942 - val_loss: 0.3328 - val_accuracy: 0.8786\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2878 - accuracy: 0.8949 - val_loss: 0.3347 - val_accuracy: 0.8768\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2864 - accuracy: 0.8952 - val_loss: 0.3325 - val_accuracy: 0.8779\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2896 - accuracy: 0.8939 - val_loss: 0.3421 - val_accuracy: 0.8753\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2827 - accuracy: 0.8971 - val_loss: 0.3417 - val_accuracy: 0.8761\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2790 - accuracy: 0.8981 - val_loss: 0.3239 - val_accuracy: 0.8826\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2746 - accuracy: 0.8999 - val_loss: 0.3223 - val_accuracy: 0.8822\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2745 - accuracy: 0.9008 - val_loss: 0.3227 - val_accuracy: 0.8838\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2795 - accuracy: 0.8976 - val_loss: 0.3288 - val_accuracy: 0.8813\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2710 - accuracy: 0.9020 - val_loss: 0.3164 - val_accuracy: 0.8853\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2702 - accuracy: 0.9014 - val_loss: 0.3165 - val_accuracy: 0.8861\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2655 - accuracy: 0.9035 - val_loss: 0.3225 - val_accuracy: 0.8833\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2664 - accuracy: 0.9028 - val_loss: 0.3179 - val_accuracy: 0.8851\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2647 - accuracy: 0.9036 - val_loss: 0.3135 - val_accuracy: 0.8857\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2613 - accuracy: 0.9054 - val_loss: 0.3234 - val_accuracy: 0.8842\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2644 - accuracy: 0.9034 - val_loss: 0.3166 - val_accuracy: 0.8850\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2635 - accuracy: 0.9033 - val_loss: 0.3127 - val_accuracy: 0.8862\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2552 - accuracy: 0.9070 - val_loss: 0.3151 - val_accuracy: 0.8850\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2599 - accuracy: 0.9055 - val_loss: 0.3204 - val_accuracy: 0.8859\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2578 - accuracy: 0.9062 - val_loss: 0.3116 - val_accuracy: 0.8877\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2511 - accuracy: 0.9083 - val_loss: 0.3068 - val_accuracy: 0.8875\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2491 - accuracy: 0.9084 - val_loss: 0.3163 - val_accuracy: 0.8872\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2504 - accuracy: 0.9078 - val_loss: 0.3217 - val_accuracy: 0.8860\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2483 - accuracy: 0.9094 - val_loss: 0.3102 - val_accuracy: 0.8883\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2471 - accuracy: 0.9090 - val_loss: 0.3098 - val_accuracy: 0.8884\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2457 - accuracy: 0.9110 - val_loss: 0.3122 - val_accuracy: 0.8897\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2462 - accuracy: 0.9099 - val_loss: 0.3128 - val_accuracy: 0.8851\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2418 - accuracy: 0.9117 - val_loss: 0.3125 - val_accuracy: 0.8874\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2439 - accuracy: 0.9107 - val_loss: 0.3173 - val_accuracy: 0.8859\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2442 - accuracy: 0.9095 - val_loss: 0.3077 - val_accuracy: 0.8886\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2375 - accuracy: 0.9132 - val_loss: 0.3079 - val_accuracy: 0.8874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6da047c7d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Compile and fit your model\n",
    "import os\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model = lenet5()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # *5\n",
    "\n",
    "# Define now our callbacks\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "\n",
    "# Finally fit the model\n",
    "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks) # read up on \"epoch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf-SqjjOyO8q"
   },
   "source": [
    "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2FTj7TSyO8q"
   },
   "source": [
    "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPjJoMQZyO8q",
    "outputId": "0ccd7adf-d2a1-4045-d07b-52c10e093b41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train with NN: 0.9125\n",
      "accuracy on test with NN: 0.8874\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 1024\n",
    "y_pred_train = to_categorical(model.predict(X_train_norm,batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "y_pred_test = to_categorical(model.predict(X_test_norm,batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "\n",
    "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat)) # Output can be significantly higher with a higher epoch\n",
    "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vulsgHiyO8q"
   },
   "source": [
    "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
    "\n",
    "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
    "* `horizontal_flip=True`\n",
    "\n",
    "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
    "\n",
    "Begin by creating an object `ImageDataGenerator` with this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:58:37.442182Z",
     "start_time": "2020-08-19T11:58:37.438397Z"
    },
    "id": "pas-fMSIyO8q"
   },
   "outputs": [],
   "source": [
    "# TODO: Instantiate an ImageDataGenerator object\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True) # Ideally should prevent overflipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7nCnu9syO8r"
   },
   "source": [
    "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zt6wXa3IyO8r",
    "outputId": "451d09d6-f6b4-453d-c35e-0dcc0a40e65b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 4s 55ms/step - loss: 0.4616 - accuracy: 0.8530 - val_loss: 0.3389 - val_accuracy: 0.8784\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 3s 45ms/step - loss: 0.3155 - accuracy: 0.8850 - val_loss: 0.3188 - val_accuracy: 0.8862\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2994 - accuracy: 0.8909 - val_loss: 0.3158 - val_accuracy: 0.8882\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2893 - accuracy: 0.8946 - val_loss: 0.3216 - val_accuracy: 0.8848\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2822 - accuracy: 0.8974 - val_loss: 0.3147 - val_accuracy: 0.8870\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2773 - accuracy: 0.8983 - val_loss: 0.3251 - val_accuracy: 0.8850\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.2755 - accuracy: 0.8990 - val_loss: 0.3079 - val_accuracy: 0.8909\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2718 - accuracy: 0.9009 - val_loss: 0.3101 - val_accuracy: 0.8861\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 3s 52ms/step - loss: 0.2652 - accuracy: 0.9024 - val_loss: 0.3054 - val_accuracy: 0.8892\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.2724 - accuracy: 0.8990 - val_loss: 0.3026 - val_accuracy: 0.8904\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2641 - accuracy: 0.9026 - val_loss: 0.3067 - val_accuracy: 0.8902\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 3s 52ms/step - loss: 0.2586 - accuracy: 0.9050 - val_loss: 0.3074 - val_accuracy: 0.8879\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2566 - accuracy: 0.9063 - val_loss: 0.3009 - val_accuracy: 0.8928\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2645 - accuracy: 0.9021 - val_loss: 0.3054 - val_accuracy: 0.8897\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 3s 52ms/step - loss: 0.2569 - accuracy: 0.9047 - val_loss: 0.3011 - val_accuracy: 0.8904\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2516 - accuracy: 0.9079 - val_loss: 0.2989 - val_accuracy: 0.8914\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 3s 50ms/step - loss: 0.2507 - accuracy: 0.9078 - val_loss: 0.3223 - val_accuracy: 0.8824\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2500 - accuracy: 0.9078 - val_loss: 0.3018 - val_accuracy: 0.8900\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2485 - accuracy: 0.9085 - val_loss: 0.2924 - val_accuracy: 0.8943\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.2424 - accuracy: 0.9116 - val_loss: 0.3013 - val_accuracy: 0.8919\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2408 - accuracy: 0.9104 - val_loss: 0.3085 - val_accuracy: 0.8888\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 3s 48ms/step - loss: 0.2399 - accuracy: 0.9117 - val_loss: 0.3002 - val_accuracy: 0.8930\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 3s 48ms/step - loss: 0.2415 - accuracy: 0.9108 - val_loss: 0.3153 - val_accuracy: 0.8865\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2365 - accuracy: 0.9120 - val_loss: 0.2977 - val_accuracy: 0.8911\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2388 - accuracy: 0.9117 - val_loss: 0.2939 - val_accuracy: 0.8961\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 3s 49ms/step - loss: 0.2344 - accuracy: 0.9130 - val_loss: 0.2920 - val_accuracy: 0.8935\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2297 - accuracy: 0.9149 - val_loss: 0.2991 - val_accuracy: 0.8926\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2282 - accuracy: 0.9163 - val_loss: 0.2904 - val_accuracy: 0.8935\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.2284 - accuracy: 0.9164 - val_loss: 0.2912 - val_accuracy: 0.8946\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2298 - accuracy: 0.9154 - val_loss: 0.2918 - val_accuracy: 0.8948\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2275 - accuracy: 0.9160 - val_loss: 0.2929 - val_accuracy: 0.8947\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 3s 45ms/step - loss: 0.2319 - accuracy: 0.9140 - val_loss: 0.2972 - val_accuracy: 0.8952\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2245 - accuracy: 0.9169 - val_loss: 0.3021 - val_accuracy: 0.8919\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2290 - accuracy: 0.9141 - val_loss: 0.3011 - val_accuracy: 0.8891\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2208 - accuracy: 0.9188 - val_loss: 0.2941 - val_accuracy: 0.8939\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2197 - accuracy: 0.9201 - val_loss: 0.2931 - val_accuracy: 0.8971\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2180 - accuracy: 0.9196 - val_loss: 0.2888 - val_accuracy: 0.8984\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2144 - accuracy: 0.9203 - val_loss: 0.2918 - val_accuracy: 0.8949\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 3s 45ms/step - loss: 0.2148 - accuracy: 0.9205 - val_loss: 0.2895 - val_accuracy: 0.8965\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2140 - accuracy: 0.9211 - val_loss: 0.2921 - val_accuracy: 0.8972\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 3s 52ms/step - loss: 0.2148 - accuracy: 0.9212 - val_loss: 0.2953 - val_accuracy: 0.8968\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.2188 - accuracy: 0.9184 - val_loss: 0.2964 - val_accuracy: 0.8953\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2158 - accuracy: 0.9205 - val_loss: 0.2882 - val_accuracy: 0.8984\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2126 - accuracy: 0.9212 - val_loss: 0.2885 - val_accuracy: 0.8995\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2103 - accuracy: 0.9217 - val_loss: 0.3051 - val_accuracy: 0.8952\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2085 - accuracy: 0.9210 - val_loss: 0.2924 - val_accuracy: 0.8972\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2066 - accuracy: 0.9243 - val_loss: 0.2891 - val_accuracy: 0.8961\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 3s 52ms/step - loss: 0.2084 - accuracy: 0.9216 - val_loss: 0.2954 - val_accuracy: 0.8960\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2042 - accuracy: 0.9240 - val_loss: 0.2965 - val_accuracy: 0.8955\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2023 - accuracy: 0.9252 - val_loss: 0.2867 - val_accuracy: 0.8978\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2053 - accuracy: 0.9249 - val_loss: 0.2949 - val_accuracy: 0.8977\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2010 - accuracy: 0.9256 - val_loss: 0.2964 - val_accuracy: 0.8976\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.1995 - accuracy: 0.9267 - val_loss: 0.2973 - val_accuracy: 0.8940\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.1989 - accuracy: 0.9269 - val_loss: 0.2960 - val_accuracy: 0.8943\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.1950 - accuracy: 0.9279 - val_loss: 0.2867 - val_accuracy: 0.8991\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.1970 - accuracy: 0.9276 - val_loss: 0.2941 - val_accuracy: 0.8952\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.1956 - accuracy: 0.9279 - val_loss: 0.2932 - val_accuracy: 0.8983\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.1990 - accuracy: 0.9256 - val_loss: 0.2916 - val_accuracy: 0.8973\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 3s 55ms/step - loss: 0.1948 - accuracy: 0.9272 - val_loss: 0.2889 - val_accuracy: 0.8999\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 0.1928 - accuracy: 0.9282 - val_loss: 0.2989 - val_accuracy: 0.8980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6cbc62fe90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: train your model\n",
    "batch_size = 1024\n",
    "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
    "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
    "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuzFke8pyO8r"
   },
   "source": [
    "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsTm86tuyO8r",
    "outputId": "fd8d7b26-639c-499a-b509-8a14f25b4320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train with CNN: 0.93085\n",
      "accuracy on test with CNN: 0.898\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size=1024\n",
    "y_pred_train = to_categorical(model.predict(X_train_norm,batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "y_pred_test = to_categorical(model.predict(X_test_norm,batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "\n",
    "#  argmax(axis=1) -- take the category that has the highest value\n",
    "#  num_classes -- each clothing item in label_class\n",
    "\n",
    "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
    "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOzkdGf7yO8s"
   },
   "source": [
    "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LeNet5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
