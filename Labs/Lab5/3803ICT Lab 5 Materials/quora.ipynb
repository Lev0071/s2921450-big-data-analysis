{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Insincere Questions Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "Quora is a popular website where anyone can ask and/or answer a question. There are more than 100 millions unique visitors per month.\n",
    "\n",
    "Like any other forum, Quora is facing a problem: toxic questions and comments.\n",
    "\n",
    "As you can imagine, Quora teams cannot check all of the Q&A by hand. So they decided to ask the data science community to help them to perform automatically insincere questions classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "This challenge was launched on Kaggle : https://www.kaggle.com/c/quora-insincere-questions-classification.\n",
    "\n",
    "Read the overall information on Kaggle. Quora provided a dataset of questions with a label, and the features are the following:\n",
    "\n",
    "+ qid: a unique identifier for each question, an hexadecimal number\n",
    "+ question_text: the text of the question\n",
    "+ target: either 1 (for insincere question) or 0\n",
    "\n",
    "In this competition, the metric used for performance evaluation is the F-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#TODO: Read the training data in CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  \\\n",
       "0  00002165364db923c7e6   \n",
       "1  000032939017120e6e44   \n",
       "2  0000412ca6e4628ce2cf   \n",
       "3  000042bf85aa498cd78e   \n",
       "4  0000455dfa3e01eae3af   \n",
       "\n",
       "                                                                       question_text  \\\n",
       "0           How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1  Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                          How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4      Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of toxic question 6.187017751787352 %\n",
      "Ratio of non toxic question 93.81298224821265 %\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the class distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0000e91571b60c2fb487</td>\n",
       "      <td>Has the United States become the largest dictatorship in the world?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>00013ceca3f624b09f42</td>\n",
       "      <td>Which babies are more sweeter to their parents? Dark skin babies or light skin babies?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0004a7fcb2bf73076489</td>\n",
       "      <td>If blacks support school choice and mandatory sentencing for criminals why don't they vote Republican?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>00052793eaa287aff1e1</td>\n",
       "      <td>I am gay boy and I love my cousin (boy). He is sexy, but I dont know what to do. He is hot, and I want to see his di**. What should I do?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>000537213b01fd77b58a</td>\n",
       "      <td>Which races have the smallest penis?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>00056d45a1ce63856fc6</td>\n",
       "      <td>Why do females find penises ugly?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0005de07b07a17046e27</td>\n",
       "      <td>How do I marry an American woman for a Green Card? How much do they charge?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>00068875d7c82a5bcf88</td>\n",
       "      <td>Why do Europeans say they're the superior race, when in fact it took them over 2,000 years until mid 19th century to surpass China's largest economy?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0006ffd99a6599ff35b3</td>\n",
       "      <td>Did Julius Caesar bring a tyrannosaurus rex on his campaigns to frighten the Celts into submission?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>00075f7061837807c69f</td>\n",
       "      <td>In what manner has Republican backing of 'states rights' been hypocritical and what ways have they actually restricted the ability of states to make their own laws?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      qid  \\\n",
       "22   0000e91571b60c2fb487   \n",
       "30   00013ceca3f624b09f42   \n",
       "110  0004a7fcb2bf73076489   \n",
       "114  00052793eaa287aff1e1   \n",
       "115  000537213b01fd77b58a   \n",
       "119  00056d45a1ce63856fc6   \n",
       "127  0005de07b07a17046e27   \n",
       "144  00068875d7c82a5bcf88   \n",
       "156  0006ffd99a6599ff35b3   \n",
       "167  00075f7061837807c69f   \n",
       "\n",
       "                                                                                                                                                            question_text  \\\n",
       "22                                                                                                    Has the United States become the largest dictatorship in the world?   \n",
       "30                                                                                 Which babies are more sweeter to their parents? Dark skin babies or light skin babies?   \n",
       "110                                                                If blacks support school choice and mandatory sentencing for criminals why don't they vote Republican?   \n",
       "114                             I am gay boy and I love my cousin (boy). He is sexy, but I dont know what to do. He is hot, and I want to see his di**. What should I do?   \n",
       "115                                                                                                                                  Which races have the smallest penis?   \n",
       "119                                                                                                                                     Why do females find penises ugly?   \n",
       "127                                                                                           How do I marry an American woman for a Green Card? How much do they charge?   \n",
       "144                 Why do Europeans say they're the superior race, when in fact it took them over 2,000 years until mid 19th century to surpass China's largest economy?   \n",
       "156                                                                   Did Julius Caesar bring a tyrannosaurus rex on his campaigns to frighten the Celts into submission?   \n",
       "167  In what manner has Republican backing of 'states rights' been hypocritical and what ways have they actually restricted the ability of states to make their own laws?   \n",
       "\n",
       "     target  \n",
       "22        1  \n",
       "30        1  \n",
       "110       1  \n",
       "114       1  \n",
       "115       1  \n",
       "119       1  \n",
       "127       1  \n",
       "144       1  \n",
       "156       1  \n",
       "167       1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "df[df.target==1].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is quite big, Let's play with a sample of 10000 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>879280</td>\n",
       "      <td>ac452e6e3f90075f2caa</td>\n",
       "      <td>Whether advances from customers are to be reinstated in the financial statements?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43285</td>\n",
       "      <td>087846c595acf81fd460</td>\n",
       "      <td>How can you get help?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740986</td>\n",
       "      <td>911f311c129684b0eb08</td>\n",
       "      <td>How does one succeed as a lecturer in medicine in a medical college in India?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472594</td>\n",
       "      <td>5c8a3fa6a63e7e1b86c8</td>\n",
       "      <td>What is the purpose behind the Yellow wallpaper?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453814</td>\n",
       "      <td>58e70e16bd6a778b8e6e</td>\n",
       "      <td>What is the problem by applying under non spp programme for diploma?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "879280  ac452e6e3f90075f2caa   \n",
       "43285   087846c595acf81fd460   \n",
       "740986  911f311c129684b0eb08   \n",
       "472594  5c8a3fa6a63e7e1b86c8   \n",
       "453814  58e70e16bd6a778b8e6e   \n",
       "\n",
       "                                                                            question_text  \\\n",
       "879280  Whether advances from customers are to be reinstated in the financial statements?   \n",
       "43285                                                               How can you get help?   \n",
       "740986      How does one succeed as a lecturer in medicine in a medical college in India?   \n",
       "472594                                   What is the purpose behind the Yellow wallpaper?   \n",
       "453814               What is the problem by applying under non spp programme for diploma?   \n",
       "\n",
       "        target  \n",
       "879280       0  \n",
       "43285        0  \n",
       "740986       0  \n",
       "472594       0  \n",
       "453814       0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "#TODO: sample 10000 questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the proportion of toxic question within our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of toxic question 5.71 %\n",
      "Ratio of non toxic question 94.28999999999999 %\n"
     ]
    }
   ],
   "source": [
    "#TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \n",
    "                       \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\",\n",
    "                       \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \n",
    "                       \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                       \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "                       \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \n",
    "                       \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
    "                       \"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \n",
    "                       \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                       \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
    "                       \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
    "                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                       \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\",\n",
    "                       \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \n",
    "                       \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
    "                       \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \n",
    "                       \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \n",
    "                       \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \n",
    "                       \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                       \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n",
    "                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                       \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "                       \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                       \"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                       \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "\n",
    "#TODO: normalize the text by using contraction mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def text_preprocess(text):\n",
    "    text = text.lower()\n",
    "    #after checking vocab_out dict we decided to aply those following replace\n",
    "    text = text.replace(\"-\", \" \").replace(\"/\", \" \").replace(\"\\\\\", \" \").replace(\"'\", \" \")\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "#TODO: you can further remove stop words and use lemmtizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>879280</td>\n",
       "      <td>ac452e6e3f90075f2caa</td>\n",
       "      <td>Whether advances from customers are to be reinstated in the financial statements?</td>\n",
       "      <td>0</td>\n",
       "      <td>[whether, advances, from, customers, are, to, be, reinstated, in, the, financial, statements]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43285</td>\n",
       "      <td>087846c595acf81fd460</td>\n",
       "      <td>How can you get help?</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, can, you, get, help]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740986</td>\n",
       "      <td>911f311c129684b0eb08</td>\n",
       "      <td>How does one succeed as a lecturer in medicine in a medical college in India?</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, does, one, succeed, as, a, lecturer, in, medicine, in, a, medical, college, in, india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472594</td>\n",
       "      <td>5c8a3fa6a63e7e1b86c8</td>\n",
       "      <td>What is the purpose behind the Yellow wallpaper?</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, is, the, purpose, behind, the, yellow, wallpaper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453814</td>\n",
       "      <td>58e70e16bd6a778b8e6e</td>\n",
       "      <td>What is the problem by applying under non spp programme for diploma?</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, is, the, problem, by, applying, under, non, spp, programme, for, diploma]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "879280  ac452e6e3f90075f2caa   \n",
       "43285   087846c595acf81fd460   \n",
       "740986  911f311c129684b0eb08   \n",
       "472594  5c8a3fa6a63e7e1b86c8   \n",
       "453814  58e70e16bd6a778b8e6e   \n",
       "\n",
       "                                                                            question_text  \\\n",
       "879280  Whether advances from customers are to be reinstated in the financial statements?   \n",
       "43285                                                               How can you get help?   \n",
       "740986      How does one succeed as a lecturer in medicine in a medical college in India?   \n",
       "472594                                   What is the purpose behind the Yellow wallpaper?   \n",
       "453814               What is the problem by applying under non spp programme for diploma?   \n",
       "\n",
       "        target  \\\n",
       "879280       0   \n",
       "43285        0   \n",
       "740986       0   \n",
       "472594       0   \n",
       "453814       0   \n",
       "\n",
       "                                                                                               tokens  \n",
       "879280  [whether, advances, from, customers, are, to, be, reinstated, in, the, financial, statements]  \n",
       "43285                                                                      [how, can, you, get, help]  \n",
       "740986   [how, does, one, succeed, as, a, lecturer, in, medicine, in, a, medical, college, in, india]  \n",
       "472594                                       [what, is, the, purpose, behind, the, yellow, wallpaper]  \n",
       "453814               [what, is, the, problem, by, applying, under, non, spp, programme, for, diploma]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[\"tokens\"] = df_sample[\"question_text\"].apply(lambda x: text_preprocess(x))\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "Should we preprocess the text with our classic methods... well not really ! First let's check what is the proportion of our document vocabulary that is taken into account by our embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function that allows to read a pretrained model and returns words and a dictionary of word embeddings\n",
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = []\n",
    "        word_to_vec_map = {}\n",
    "        bad = 0\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.append(curr_word)\n",
    "            try :\n",
    "                word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            except ValueError:\n",
    "                bad +=1\n",
    "            \n",
    "        print(f'There are {bad} bad lines')\n",
    "    return words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 bad lines\n"
     ]
    }
   ],
   "source": [
    "#TODO: Load Glove embedding\n",
    "glove_file = \"...glove.6B.50d.txt\"\n",
    "words, word_to_vec_map = read_glove_vecs(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "#TODO: check if any token is not in the Glove embedding \n",
    "\n",
    "def is_in_vocab(tokens_list):\n",
    "    in_vocab = {}\n",
    "    out_vocab = {}\n",
    "    ...\n",
    "    out_vocab_ordered = sorted(out_vocab.items(), key=operator.itemgetter(1))[::-1]\n",
    "    return in_vocab, out_vocab_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of words in word embedding vocab:  93.68450082735798 %\n",
      "proportion of words not in word embedding vocab:  6.3154991726420295 %\n"
     ]
    }
   ],
   "source": [
    "text = np.array(df_sample.tokens)\n",
    "in_vocab, out_vocab = is_in_vocab(text)\n",
    "\n",
    "in_vocab_ratio = len(in_vocab.keys())/(len(in_vocab.keys()) + len(out_vocab))\n",
    "out_vocab_ratio = len(out_vocab)/(len(in_vocab.keys()) + len(out_vocab))\n",
    "                                                             \n",
    "print(\"proportion of words in word embedding vocab: \", in_vocab_ratio*100, \"%\")\n",
    "print(\"proportion of words not in word embedding vocab: \", out_vocab_ratio*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quorans', 9),\n",
       " ('cryptocurrencies', 7),\n",
       " ('kvpy', 7),\n",
       " ('wbjee', 5),\n",
       " ('cryptocurrency', 5),\n",
       " ('brexit', 5),\n",
       " ('bitsat', 5),\n",
       " ('blockchain', 4),\n",
       " ('upvotes', 4),\n",
       " ('afsb', 3),\n",
       " ('infty', 3),\n",
       " ('kyc', 3),\n",
       " ('chsl', 3),\n",
       " ('async', 3),\n",
       " ('shopify', 3),\n",
       " ('viteee', 3),\n",
       " ('chitkara', 3),\n",
       " ('infp', 3),\n",
       " ('ethereum', 3),\n",
       " ('bnbr', 3),\n",
       " ('articleship', 3),\n",
       " ('flipkart', 3),\n",
       " ('josaa', 3),\n",
       " ('afcat', 3),\n",
       " ('offcampus', 2),\n",
       " ('igdtuw', 2),\n",
       " ('admirial', 2),\n",
       " ('tnpsc', 2),\n",
       " ('narcassist', 2),\n",
       " ('odsp', 2),\n",
       " ('rightarrow', 2),\n",
       " ('iiest', 2),\n",
       " ('covarient', 2),\n",
       " ('marksheet', 2),\n",
       " ('apist', 2),\n",
       " ('tution', 2),\n",
       " ('homolysis', 2),\n",
       " ('sqrt', 2),\n",
       " ('mblog', 2),\n",
       " ('aadhaar', 2),\n",
       " ('hairfall', 2),\n",
       " ('aemon', 2),\n",
       " ('katachi', 2),\n",
       " ('cibil', 2),\n",
       " ('redmi', 2),\n",
       " ('oneplus', 2),\n",
       " ('litecoin', 2),\n",
       " ('aadhar', 2),\n",
       " ('vajiram', 2),\n",
       " ('starflower', 2),\n",
       " ('udemy', 2),\n",
       " ('upvote', 2),\n",
       " ('ntse', 2),\n",
       " ('hotstar', 2),\n",
       " ('kaggle', 2),\n",
       " ('mht', 2),\n",
       " ('paytm', 2),\n",
       " ('masterbate', 2),\n",
       " ('demonetisation', 2),\n",
       " ('intrest', 2),\n",
       " ('iift', 2),\n",
       " ('nqso', 2),\n",
       " ('cryptos', 2),\n",
       " ('servomotor', 2),\n",
       " ('backlinks', 2),\n",
       " ('iitjee', 2),\n",
       " ('rvce', 2),\n",
       " ('psycopath', 2),\n",
       " ('blowjob', 2),\n",
       " ('waitlisted', 2),\n",
       " ('kgp', 2),\n",
       " ('romantism', 1),\n",
       " ('emojis', 1),\n",
       " ('denga', 1),\n",
       " ('puku', 1),\n",
       " ('thig', 1),\n",
       " ('growt', 1),\n",
       " ('khudh', 1),\n",
       " ('alwllays', 1),\n",
       " ('antropology', 1),\n",
       " ('wokr', 1),\n",
       " ('synchronizers', 1),\n",
       " ('swachh', 1),\n",
       " ('nutricious', 1),\n",
       " ('harrestment', 1),\n",
       " ('foodpanda', 1),\n",
       " ('apostolina', 1),\n",
       " ('whuch', 1),\n",
       " ('cerramic', 1),\n",
       " ('penten', 1),\n",
       " ('acylglycerol', 1),\n",
       " ('vairagi', 1),\n",
       " ('tuepee', 1),\n",
       " ('zoella', 1),\n",
       " ('coinbase', 1),\n",
       " ('krzanichs', 1),\n",
       " ('supratentorial', 1),\n",
       " ('mppsc', 1),\n",
       " ('exempler', 1),\n",
       " ('webservers', 1),\n",
       " ('weatherstrip', 1),\n",
       " ('koniku', 1),\n",
       " ('omegle', 1),\n",
       " ('mesosaurus', 1),\n",
       " ('flexipool', 1),\n",
       " ('traki', 1),\n",
       " ('ekt', 1),\n",
       " ('pytorch', 1),\n",
       " ('slangs', 1),\n",
       " ('stonger', 1),\n",
       " ('codecademy', 1),\n",
       " ('iitm', 1),\n",
       " ('monetise', 1),\n",
       " ('fnaf', 1),\n",
       " ('wakesurfers', 1),\n",
       " ('educe', 1),\n",
       " ('breakxit', 1),\n",
       " ('spankophile', 1),\n",
       " ('banguluru', 1),\n",
       " ('rockerfeller', 1),\n",
       " ('stuctural', 1),\n",
       " ('blocksblocks', 1),\n",
       " ('wagamese', 1),\n",
       " ('microsemi', 1),\n",
       " ('posiedon', 1),\n",
       " ('oportunities', 1),\n",
       " ('tzh', 1),\n",
       " ('algerbra', 1),\n",
       " ('cyberpowerpc', 1),\n",
       " ('prefrence', 1),\n",
       " ('pepare', 1),\n",
       " ('brightedge', 1),\n",
       " ('diacap', 1),\n",
       " ('weeabo', 1),\n",
       " ('miracast', 1),\n",
       " ('slove', 1),\n",
       " ('maingear', 1),\n",
       " ('originpc', 1),\n",
       " ('ayushi', 1),\n",
       " ('yenar', 1),\n",
       " ('kuthun', 1),\n",
       " ('pohryat', 1),\n",
       " ('skrein', 1),\n",
       " ('recruitees', 1),\n",
       " ('preboards', 1),\n",
       " ('ibps', 1),\n",
       " ('zedge', 1),\n",
       " ('chatbots', 1),\n",
       " ('aspergers', 1),\n",
       " ('emie', 1),\n",
       " ('knowble', 1),\n",
       " ('resnet', 1),\n",
       " ('alexnet', 1),\n",
       " ('sandiaga', 1),\n",
       " ('prononce', 1),\n",
       " ('rosiere', 1),\n",
       " ('corrrect', 1),\n",
       " ('taekwon', 1),\n",
       " ('aarop', 1),\n",
       " ('narindera', 1),\n",
       " ('misiles', 1),\n",
       " ('webdriver', 1),\n",
       " ('mnnit', 1),\n",
       " ('csam', 1),\n",
       " ('undergraduation', 1),\n",
       " ('ocer', 1),\n",
       " ('gymming', 1),\n",
       " ('purecon', 1),\n",
       " ('redpandas', 1),\n",
       " ('pankhuri', 1),\n",
       " ('digipad', 1),\n",
       " ('qtp', 1),\n",
       " ('stackoverflow', 1),\n",
       " ('dharmacharya', 1),\n",
       " ('awarness', 1),\n",
       " ('designet', 1),\n",
       " ('suided', 1),\n",
       " ('differerence', 1),\n",
       " ('researchgate', 1),\n",
       " ('gravityof', 1),\n",
       " ('savox', 1),\n",
       " ('heterolysis', 1),\n",
       " ('coachings', 1),\n",
       " ('zonule', 1),\n",
       " ('persue', 1),\n",
       " ('akward', 1),\n",
       " ('lumosity', 1),\n",
       " ('fexet', 1),\n",
       " ('eindiawholesale', 1),\n",
       " ('isocolon', 1),\n",
       " ('shouldnt', 1),\n",
       " ('mbappe', 1),\n",
       " ('monarquist', 1),\n",
       " ('romenia', 1),\n",
       " ('moviments', 1),\n",
       " ('restaure', 1),\n",
       " ('scamsters', 1),\n",
       " ('scandinavic', 1),\n",
       " ('iwant', 1),\n",
       " ('amnio', 1),\n",
       " ('jobstreet', 1),\n",
       " ('annimation', 1),\n",
       " ('sysconfig', 1),\n",
       " ('sattelites', 1),\n",
       " ('magmatter', 1),\n",
       " ('unfollow', 1),\n",
       " ('wallabhai', 1),\n",
       " ('quicktransfer', 1),\n",
       " ('clssses', 1),\n",
       " ('breaktrough', 1),\n",
       " ('compulsorilynotify', 1),\n",
       " ('zyzz', 1),\n",
       " ('sexwith', 1),\n",
       " ('iisers', 1),\n",
       " ('tajmahal', 1),\n",
       " ('chemtrails', 1),\n",
       " ('maurititus', 1),\n",
       " ('opencv', 1),\n",
       " ('aimals', 1),\n",
       " ('phosphoglycerate', 1),\n",
       " ('bisphosphoglycerate', 1),\n",
       " ('mystry', 1),\n",
       " ('kylo', 1),\n",
       " ('whatis', 1),\n",
       " ('cocopeat', 1),\n",
       " ('obession', 1),\n",
       " ('seborrhoeic', 1),\n",
       " ('acetylglycine', 1),\n",
       " ('kxip', 1),\n",
       " ('motherhave', 1),\n",
       " ('chalenged', 1),\n",
       " ('othordonoic', 1),\n",
       " ('recipocate', 1),\n",
       " ('magnesuim', 1),\n",
       " ('berylluim', 1),\n",
       " ('hydroboric', 1),\n",
       " ('imnt', 1),\n",
       " ('kalamkari', 1),\n",
       " ('completly', 1),\n",
       " ('sjce', 1),\n",
       " ('infps', 1),\n",
       " ('ascience', 1),\n",
       " ('nmims', 1),\n",
       " ('microaffirmations', 1),\n",
       " ('microagressions', 1),\n",
       " ('micromessaging', 1),\n",
       " ('underwera', 1),\n",
       " ('pokémons', 1),\n",
       " ('amarvilas', 1),\n",
       " ('sleap', 1),\n",
       " ('threadmill', 1),\n",
       " ('nptel', 1),\n",
       " ('isgood', 1),\n",
       " ('stsrt', 1),\n",
       " ('thoughful', 1),\n",
       " ('djt', 1),\n",
       " ('epfo', 1),\n",
       " ('cieling', 1),\n",
       " ('draxler', 1),\n",
       " ('rashford', 1),\n",
       " ('cfib', 1),\n",
       " ('ultraskyn', 1),\n",
       " ('mirpuri', 1),\n",
       " ('cintiq', 1),\n",
       " ('keylength', 1),\n",
       " ('restraunts', 1),\n",
       " ('karmasthan', 1),\n",
       " ('currupt', 1),\n",
       " ('caugched', 1),\n",
       " ('collegei', 1),\n",
       " ('resonanace', 1),\n",
       " ('prperation', 1),\n",
       " ('whaat', 1),\n",
       " ('diebetic', 1),\n",
       " ('pyaari', 1),\n",
       " ('hinjewadi', 1),\n",
       " ('earthers', 1),\n",
       " ('partime', 1),\n",
       " ('alaxander', 1),\n",
       " ('ebiz', 1),\n",
       " ('pesu', 1),\n",
       " ('æsahættr', 1),\n",
       " ('hippoptamos', 1),\n",
       " ('compulsary', 1),\n",
       " ('irrecoverably', 1),\n",
       " ('plennum', 1),\n",
       " ('oxyacids', 1),\n",
       " ('quara', 1),\n",
       " ('cefcu', 1),\n",
       " ('fincial', 1),\n",
       " ('taxify', 1),\n",
       " ('crytocurreny', 1),\n",
       " ('niser', 1),\n",
       " ('badaganadu', 1),\n",
       " ('sibm', 1),\n",
       " ('coldand', 1),\n",
       " ('knes', 1),\n",
       " ('feelmy', 1),\n",
       " ('unhide', 1),\n",
       " ('moq', 1),\n",
       " ('preparatioj', 1),\n",
       " ('folowers', 1),\n",
       " ('yygs', 1),\n",
       " ('actully', 1),\n",
       " ('gadge', 1),\n",
       " ('piths', 1),\n",
       " ('atelactasis', 1),\n",
       " ('mharie', 1),\n",
       " ('dzwonkowska', 1),\n",
       " ('scince', 1),\n",
       " ('methocarbamol', 1),\n",
       " ('bonafied', 1),\n",
       " ('fiitjee', 1),\n",
       " ('uoft', 1),\n",
       " ('continuosly', 1),\n",
       " ('redundent', 1),\n",
       " ('parkerize', 1),\n",
       " ('snapchatters', 1),\n",
       " ('mahahatma', 1),\n",
       " ('basefont', 1),\n",
       " ('targrt', 1),\n",
       " ('tilki', 1),\n",
       " ('aleyna', 1),\n",
       " ('silverwear', 1),\n",
       " ('agarsen', 1),\n",
       " ('iocl', 1),\n",
       " ('mannada', 1),\n",
       " ('shitts', 1),\n",
       " ('schizophreniform', 1),\n",
       " ('bhaijaan', 1),\n",
       " ('impassibility', 1),\n",
       " ('yourquote', 1),\n",
       " ('pentagıon', 1),\n",
       " ('shanidev', 1),\n",
       " ('inprovement', 1),\n",
       " ('blowjobs', 1),\n",
       " ('photobiomodulation', 1),\n",
       " ('narcicist', 1),\n",
       " ('nicmar', 1),\n",
       " ('盧麗安', 1),\n",
       " ('trumpie', 1),\n",
       " ('selfie', 1),\n",
       " ('nanoray', 1),\n",
       " ('carbonex', 1),\n",
       " ('fullfll', 1),\n",
       " ('upse', 1),\n",
       " ('sopport', 1),\n",
       " ('fathersday', 1),\n",
       " ('genjutsu', 1),\n",
       " ('speedcrafts', 1),\n",
       " ('pilloo', 1),\n",
       " ('scolarship', 1),\n",
       " ('crieteria', 1),\n",
       " ('solecism', 1),\n",
       " ('holotropic', 1),\n",
       " ('svnit', 1),\n",
       " ('blacklights', 1),\n",
       " ('magento', 1),\n",
       " ('evlution', 1),\n",
       " ('differece', 1),\n",
       " ('monile', 1),\n",
       " ('uppcs', 1),\n",
       " ('rabada', 1),\n",
       " ('insuffucient', 1),\n",
       " ('etrugul', 1),\n",
       " ('qrae', 1),\n",
       " ('wjen', 1),\n",
       " ('statiatical', 1),\n",
       " ('stereoviewer', 1),\n",
       " ('pdpu', 1),\n",
       " ('jiit', 1),\n",
       " ('suplli', 1),\n",
       " ('ethenol', 1),\n",
       " ('methenol', 1),\n",
       " ('distiguised', 1),\n",
       " ('postie', 1),\n",
       " ('suleka', 1),\n",
       " ('cocubes', 1),\n",
       " ('elitmus', 1),\n",
       " ('situable', 1),\n",
       " ('iitk', 1),\n",
       " ('ecopsychology', 1),\n",
       " ('telikinesis', 1),\n",
       " ('durentho', 1),\n",
       " ('scoreca', 1),\n",
       " ('soundtouch', 1),\n",
       " ('ableist', 1),\n",
       " ('cdsl', 1),\n",
       " ('pushbullet', 1),\n",
       " ('nichabhanarajyoga', 1),\n",
       " ('molestor', 1),\n",
       " ('harrassor', 1),\n",
       " ('refregerated', 1),\n",
       " ('hootsuite', 1),\n",
       " ('geling', 1),\n",
       " ('ifmy', 1),\n",
       " ('mugup', 1),\n",
       " ('umich', 1),\n",
       " ('qumunity', 1),\n",
       " ('alkalyn', 1),\n",
       " ('kre', 1),\n",
       " ('unfriend', 1),\n",
       " ('uiit', 1),\n",
       " ('punnishment', 1),\n",
       " ('murcury', 1),\n",
       " ('aplogy', 1),\n",
       " ('truff', 1),\n",
       " ('outperfom', 1),\n",
       " ('factorize', 1),\n",
       " ('itelligence', 1),\n",
       " ('diabitis', 1),\n",
       " ('adzap', 1),\n",
       " ('sebagh', 1),\n",
       " ('sneakerhead', 1),\n",
       " ('reportes', 1),\n",
       " ('casterly', 1),\n",
       " ('cercei', 1),\n",
       " ('dother', 1),\n",
       " ('instaed', 1),\n",
       " ('foodstamps', 1),\n",
       " ('oxwall', 1),\n",
       " ('tolaram', 1),\n",
       " ('exhisting', 1),\n",
       " ('demylination', 1),\n",
       " ('paracentral', 1),\n",
       " ('quantasome', 1),\n",
       " ('cerelac', 1),\n",
       " ('pggcg', 1),\n",
       " ('shopkins', 1),\n",
       " ('flebicite', 1),\n",
       " ('fack', 1),\n",
       " ('鸡汤文', 1),\n",
       " ('jto', 1),\n",
       " ('unliked', 1),\n",
       " ('diifcult', 1),\n",
       " ('seratonin', 1),\n",
       " ('excisional', 1),\n",
       " ('csgo', 1),\n",
       " ('passout', 1),\n",
       " ('taugh', 1),\n",
       " ('mhrm', 1),\n",
       " ('kharaghpur', 1),\n",
       " ('gentel', 1),\n",
       " ('soulpancake', 1),\n",
       " ('neuralink', 1),\n",
       " ('hyperloop', 1),\n",
       " ('míriel', 1),\n",
       " ('ossd', 1),\n",
       " ('coorelation', 1),\n",
       " ('payoneer', 1),\n",
       " ('lahren', 1),\n",
       " ('feminazism', 1),\n",
       " ('niftem', 1),\n",
       " ('sonometer', 1),\n",
       " ('intps', 1),\n",
       " ('nadsat', 1),\n",
       " ('congratultions', 1),\n",
       " ('rubix', 1),\n",
       " ('jaasoos', 1),\n",
       " ('kibbosh', 1),\n",
       " ('voweless', 1),\n",
       " ('meritorio', 1),\n",
       " ('physice', 1),\n",
       " ('shcf', 1),\n",
       " ('sucf', 1),\n",
       " ('eletric', 1),\n",
       " ('dissapears', 1),\n",
       " ('xbuntu', 1),\n",
       " ('roits', 1),\n",
       " ('crotchless', 1),\n",
       " ('ctanujit', 1),\n",
       " ('wikitribune', 1),\n",
       " ('shooted', 1),\n",
       " ('documentry', 1),\n",
       " ('mastrubate', 1),\n",
       " ('autonony', 1),\n",
       " ('topcoder', 1),\n",
       " ('neovagina', 1),\n",
       " ('khalistanis', 1),\n",
       " ('behide', 1),\n",
       " ('bhappa', 1),\n",
       " ('apbs', 1),\n",
       " ('pagophagia', 1),\n",
       " ('whatmakes', 1),\n",
       " ('unbond', 1),\n",
       " ('wolfepack', 1),\n",
       " ('crosstreck', 1),\n",
       " ('fluild', 1),\n",
       " ('prespective', 1),\n",
       " ('trotzky', 1),\n",
       " ('trotzkyists', 1),\n",
       " ('psir', 1),\n",
       " ('shubhra', 1),\n",
       " ('prifix', 1),\n",
       " ('inorder', 1),\n",
       " ('juit', 1),\n",
       " ('tgere', 1),\n",
       " ('mmmut', 1),\n",
       " ('vark', 1),\n",
       " ('ɔj', 1),\n",
       " ('æj', 1),\n",
       " ('attemping', 1),\n",
       " ('meruem', 1),\n",
       " ('rcnn', 1),\n",
       " ('roialign', 1),\n",
       " ('refractometers', 1),\n",
       " ('afria', 1),\n",
       " ('alshamsi', 1),\n",
       " ('hagushipta', 1),\n",
       " ('paguri', 1),\n",
       " ('inx', 1),\n",
       " ('hyperv', 1),\n",
       " ('dosent', 1),\n",
       " ('unnati', 1),\n",
       " ('elçin', 1),\n",
       " ('stdr', 1),\n",
       " ('dhmis', 1),\n",
       " ('swordfighters', 1),\n",
       " ('vacucum', 1),\n",
       " ('mistakely', 1),\n",
       " ('multinodullar', 1),\n",
       " ('gfti', 1),\n",
       " ('zensar', 1),\n",
       " ('nadella', 1),\n",
       " ('enterprizes', 1),\n",
       " ('whay', 1),\n",
       " ('pharmoceutical', 1),\n",
       " ('rigths', 1),\n",
       " ('aiats', 1),\n",
       " ('uwhy', 1),\n",
       " ('nodemcu', 1),\n",
       " ('transcontintal', 1),\n",
       " ('methology', 1),\n",
       " ('altcoins', 1),\n",
       " ('naery', 1),\n",
       " ('naerys', 1),\n",
       " ('daeron', 1),\n",
       " ('libmosquitto', 1),\n",
       " ('persy', 1),\n",
       " ('buyed', 1),\n",
       " ('bettr', 1),\n",
       " ('laliga', 1),\n",
       " ('tvl', 1),\n",
       " ('barbaria', 1),\n",
       " ('aceking', 1),\n",
       " ('invasio', 1),\n",
       " ('formular', 1),\n",
       " ('separatory', 1),\n",
       " ('wabot', 1),\n",
       " ('interective', 1),\n",
       " ('blezer', 1),\n",
       " ('oksibil', 1),\n",
       " ('zettl', 1),\n",
       " ('jphow', 1),\n",
       " ('carier', 1),\n",
       " ('belgavi', 1),\n",
       " ('roomate', 1),\n",
       " ('gatw', 1),\n",
       " ('conversate', 1),\n",
       " ('videospinblasterpro', 1),\n",
       " ('bemilendu', 1),\n",
       " ('zkteco', 1),\n",
       " ('mortgafe', 1),\n",
       " ('calloc', 1),\n",
       " ('malloc', 1),\n",
       " ('cosx', 1),\n",
       " ('sinx', 1),\n",
       " ('misophonia', 1),\n",
       " ('rgsc', 1),\n",
       " ('syallabus', 1),\n",
       " ('inoi', 1),\n",
       " ('zco', 1),\n",
       " ('laravel', 1),\n",
       " ('cannada', 1),\n",
       " ('couler', 1),\n",
       " ('wtat', 1),\n",
       " ('deltafosb', 1),\n",
       " ('bhubhaneshwar', 1),\n",
       " ('shulgold', 1),\n",
       " ('naptol', 1),\n",
       " ('infitine', 1),\n",
       " ('posdoctoral', 1),\n",
       " ('doggerland', 1),\n",
       " ('mexic', 1),\n",
       " ('viza', 1),\n",
       " ('kasol', 1),\n",
       " ('boruto', 1),\n",
       " ('ehy', 1),\n",
       " ('nesraway', 1),\n",
       " ('inbreed', 1),\n",
       " ('acturial', 1),\n",
       " ('unempathetic', 1),\n",
       " ('jasoos', 1),\n",
       " ('karky', 1),\n",
       " ('frenchaisie', 1),\n",
       " ('mathspro', 1),\n",
       " ('onother', 1),\n",
       " ('eyevision', 1),\n",
       " ('cradre', 1),\n",
       " ('hōkū', 1),\n",
       " ('activies', 1),\n",
       " ('bcaas', 1),\n",
       " ('idk', 1),\n",
       " ('cacilhas', 1),\n",
       " ('mitm', 1),\n",
       " ('invento', 1),\n",
       " ('yamcha', 1),\n",
       " ('zomato', 1),\n",
       " ('ravula', 1),\n",
       " ('finaces', 1),\n",
       " ('odoo', 1),\n",
       " ('applock', 1),\n",
       " ('stidy', 1),\n",
       " ('peroids', 1),\n",
       " ('chloestrol', 1),\n",
       " ('mongrelism', 1),\n",
       " ('physcis', 1),\n",
       " ('revaluationresult', 1),\n",
       " ('fearsomeness', 1),\n",
       " ('zentangle', 1),\n",
       " ('dansko', 1),\n",
       " ('kainerugaba', 1),\n",
       " ('muhoozi', 1),\n",
       " ('sended', 1),\n",
       " ('ptrograms', 1),\n",
       " ('venmo', 1),\n",
       " ('secab', 1),\n",
       " ('altucher', 1),\n",
       " ('superiour', 1),\n",
       " ('killswhy', 1),\n",
       " ('prepareing', 1),\n",
       " ('quantative', 1),\n",
       " ('deegree', 1),\n",
       " ('jframe', 1),\n",
       " ('naswiz', 1),\n",
       " ('sinic', 1),\n",
       " ('nadagam', 1),\n",
       " ('pantography', 1),\n",
       " ('redimo', 1),\n",
       " ('intilligent', 1),\n",
       " ('muschel', 1),\n",
       " ('ucranian', 1),\n",
       " ('ringworms', 1),\n",
       " ('microdeletion', 1),\n",
       " ('kulashekara', 1),\n",
       " ('tingjian', 1),\n",
       " ('abcli', 1),\n",
       " ('sticinging', 1),\n",
       " ('downvote', 1),\n",
       " ('medision', 1),\n",
       " ('atme', 1),\n",
       " ('nanoknife', 1),\n",
       " ('quoran', 1),\n",
       " ('sandwhiches', 1),\n",
       " ('nibm', 1),\n",
       " ('aversed', 1),\n",
       " ('comminuted', 1),\n",
       " ('tollroad', 1),\n",
       " ('sightof', 1),\n",
       " ('hypermetropia', 1),\n",
       " ('hyd', 1),\n",
       " ('ylp', 1),\n",
       " ('sarcs', 1),\n",
       " ('spectrometre', 1),\n",
       " ('anthrone', 1),\n",
       " ('embessy', 1),\n",
       " ('accepeted', 1),\n",
       " ('liek', 1),\n",
       " ('ceeb', 1),\n",
       " ('agnathostomes', 1),\n",
       " ('ostracoderms', 1),\n",
       " ('flyy', 1),\n",
       " ('lumpiang', 1),\n",
       " ('adresss', 1),\n",
       " ('matricies', 1),\n",
       " ('ballpen', 1),\n",
       " ('attitud', 1),\n",
       " ('afffect', 1),\n",
       " ('aftee', 1),\n",
       " ('azidothymidine', 1),\n",
       " ('cbcinnovis', 1),\n",
       " ('microsotf', 1),\n",
       " ('dextrostat', 1),\n",
       " ('coomon', 1),\n",
       " ('fundamentaly', 1),\n",
       " ('ashlesha', 1),\n",
       " ('fuckis', 1),\n",
       " ('diarization', 1),\n",
       " ('becu', 1),\n",
       " ('basetao', 1),\n",
       " ('jfbees', 1),\n",
       " ('tiptrans', 1),\n",
       " ('bhakts', 1),\n",
       " ('bettter', 1),\n",
       " ('sqoop', 1),\n",
       " ('غنج', 1),\n",
       " ('ענג', 1),\n",
       " ('buotique', 1),\n",
       " ('dornish', 1),\n",
       " ('jelousy', 1),\n",
       " ('sussessful', 1),\n",
       " ('scooty', 1),\n",
       " ('rsus', 1),\n",
       " ('dwarvish', 1),\n",
       " ('oakenshield', 1),\n",
       " ('convalidation', 1),\n",
       " ('palihapitiya', 1),\n",
       " ('chamath', 1),\n",
       " ('dhalls', 1),\n",
       " ('cliquey', 1),\n",
       " ('greendot', 1),\n",
       " ('dietcet', 1),\n",
       " ('pluralsight', 1),\n",
       " ('secur', 1),\n",
       " ('ambivert', 1),\n",
       " ('empathising', 1),\n",
       " ('adityanath', 1),\n",
       " ('wfirst', 1),\n",
       " ('giggers', 1),\n",
       " ('soilder', 1),\n",
       " ('gymnopedist', 1),\n",
       " ('isit', 1),\n",
       " ('neostrata', 1),\n",
       " ('pranic', 1),\n",
       " ('pureit', 1),\n",
       " ('ladyboy', 1),\n",
       " ('shishupala', 1),\n",
       " ('ovascience', 1),\n",
       " ('iₙ', 1),\n",
       " ('ⁿ', 1),\n",
       " ('fibriod', 1),\n",
       " ('grts', 1),\n",
       " ('uitvoeren', 1),\n",
       " ('betaling', 1),\n",
       " ('orbmsce', 1),\n",
       " ('comedk', 1),\n",
       " ('hetotrophs', 1),\n",
       " ('maipal', 1),\n",
       " ('endsem', 1),\n",
       " ('molarity', 1),\n",
       " ('presipitate', 1),\n",
       " ('disapate', 1),\n",
       " ('pyrokenisis', 1),\n",
       " ('hackerearth', 1),\n",
       " ('hackerrank', 1),\n",
       " ('cortizone', 1),\n",
       " ('nitk', 1),\n",
       " ('catcall', 1),\n",
       " ('gramatically', 1),\n",
       " ('phosphodiestrase', 1),\n",
       " ('rocksdb', 1),\n",
       " ('diploblastic', 1),\n",
       " ('provdes', 1),\n",
       " ('watz', 1),\n",
       " ('vaishanism', 1),\n",
       " ('imessages', 1),\n",
       " ('subreddits', 1),\n",
       " ('onexox', 1),\n",
       " ('vigamox', 1),\n",
       " ('proffesions', 1),\n",
       " ('aktu', 1),\n",
       " ('tabarani', 1),\n",
       " ('deuniversitized', 1),\n",
       " ('lakshmaiah', 1),\n",
       " ('stephenians', 1),\n",
       " ('elliminate', 1),\n",
       " ('archaemenid', 1),\n",
       " ('guldan', 1),\n",
       " ('liplock', 1),\n",
       " ('hidssum', 1),\n",
       " ('uibezier', 1),\n",
       " ('daca', 1),\n",
       " ('thepeople', 1),\n",
       " ('decices', 1),\n",
       " ('gaslighting', 1),\n",
       " ('baleno', 1),\n",
       " ('policitians', 1),\n",
       " ('gdpr', 1),\n",
       " ('emeishan', 1),\n",
       " ('neurbion', 1),\n",
       " ('byke', 1),\n",
       " ('brindavanam', 1),\n",
       " ('androgel', 1),\n",
       " ('protonema', 1),\n",
       " ('neonazism', 1),\n",
       " ('cosidered', 1),\n",
       " ('invadad', 1),\n",
       " ('infi', 1),\n",
       " ('councilling', 1),\n",
       " ('kyurem', 1),\n",
       " ('doklam', 1),\n",
       " ('woodcrafting', 1),\n",
       " ('metaphysicists', 1),\n",
       " ('ofany', 1),\n",
       " ('cfrs', 1),\n",
       " ('shephered', 1),\n",
       " ('ipill', 1),\n",
       " ('reconize', 1),\n",
       " ('iiser', 1),\n",
       " ('cluding', 1),\n",
       " ('iiscian', 1),\n",
       " ('makaritoru', 1),\n",
       " ('dhgate', 1),\n",
       " ('obhects', 1),\n",
       " ('expierence', 1),\n",
       " ('navratna', 1),\n",
       " ('kadyrovs', 1),\n",
       " ('iitian', 1),\n",
       " ('pastebin', 1),\n",
       " ('xdddddddd', 1),\n",
       " ('rawr', 1),\n",
       " ('milfs', 1),\n",
       " ('implicationfor', 1),\n",
       " ('cuttoff', 1),\n",
       " ('vansanten', 1),\n",
       " ('gniot', 1),\n",
       " ('crvo', 1),\n",
       " ('moisturiser', 1),\n",
       " ('dickheads', 1),\n",
       " ('aodd', 1),\n",
       " ('directflo', 1),\n",
       " ('realitism', 1),\n",
       " ('margilan', 1),\n",
       " ('ollivander', 1),\n",
       " ('aligator', 1),\n",
       " ('qoura', 1),\n",
       " ('emethyst', 1),\n",
       " ('faeria', 1),\n",
       " ('bezo', 1),\n",
       " ('intollerently', 1),\n",
       " ('iqr', 1),\n",
       " ('clickes', 1),\n",
       " ('pyscho', 1),\n",
       " ('มวยไทย', 1),\n",
       " ('นเรศวร', 1),\n",
       " ('astroid', 1),\n",
       " ('coricidin', 1),\n",
       " ('maintaince', 1),\n",
       " ('pbns', 1),\n",
       " ('bolsonaro', 1),\n",
       " ('realdo', 1),\n",
       " ('cerato', 1),\n",
       " ('beaurocracy', 1),\n",
       " ('desprate', 1),\n",
       " ('glenunga', 1),\n",
       " ('qlikview', 1),\n",
       " ('monetizes', 1),\n",
       " ('snoke', 1),\n",
       " ('healthify', 1),\n",
       " ('trumpism', 1),\n",
       " ('beerus', 1),\n",
       " ('raegan', 1),\n",
       " ('traimed', 1),\n",
       " ('gitam', 1),\n",
       " ('inprove', 1),\n",
       " ('comicstrip', 1),\n",
       " ('gurewitch', 1),\n",
       " ('bedaquiline', 1),\n",
       " ('vistara', 1),\n",
       " ('hijama', 1),\n",
       " ('upvoter', 1),\n",
       " ('dankest', 1),\n",
       " ('shtf', 1),\n",
       " ('cerebllum', 1),\n",
       " ('wuth', 1),\n",
       " ('biocarbonate', 1),\n",
       " ('chatbot', 1),\n",
       " ('prematureclosure', 1),\n",
       " ('sarks', 1),\n",
       " ('mnit', 1),\n",
       " ('deareated', 1),\n",
       " ('placdment', 1),\n",
       " ('inmo', 1),\n",
       " ('ebuddy', 1),\n",
       " ('epiduo', 1),\n",
       " ('hondsome', 1),\n",
       " ('remdes', 1),\n",
       " ('capit', 1),\n",
       " ('hiaku', 1),\n",
       " ('qspiders', 1),\n",
       " ('bipc', 1),\n",
       " ('avetage', 1),\n",
       " ('buscopan', 1),\n",
       " ('gdce', 1),\n",
       " ('condemed', 1),\n",
       " ('syrio', 1),\n",
       " ('appsally', 1),\n",
       " ('softaculous', 1),\n",
       " ('pogona', 1),\n",
       " ('cpec', 1),\n",
       " ('infoblox', 1),\n",
       " ('stinkier', 1),\n",
       " ('epulis', 1),\n",
       " ('hyperscale', 1),\n",
       " ('olympiades', 1),\n",
       " ('enterance', 1),\n",
       " ('sanik', 1),\n",
       " ('tapmi', 1),\n",
       " ('ifmr', 1),\n",
       " ('polimi', 1),\n",
       " ('volumizing', 1),\n",
       " ('stucked', 1),\n",
       " ('jogwa', 1),\n",
       " ('bingobox', 1),\n",
       " ('misarticulation', 1),\n",
       " ('worring', 1),\n",
       " ('dragneel', 1),\n",
       " ('momoshiki', 1),\n",
       " ('ulitmate', 1),\n",
       " ('minijets', 1),\n",
       " ('ikm', 1),\n",
       " ('domestical', 1),\n",
       " ('yaers', 1),\n",
       " ('provings', 1),\n",
       " ('philosohy', 1),\n",
       " ('overcaring', 1)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(OPTIONAL)\n",
    "How to improve this rate:\n",
    "* Should we remove punctuation ? \n",
    "* Should we remove numbers ? \n",
    "* Should we remove stopwords ? \n",
    "* Should we Stemmatize / Lemmatize ?\n",
    "\n",
    "We could also use TextBlob for mispellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the embedding for each question text from word embeddings\n",
    "def get_vector_from(tokens):\n",
    "    word_vect = np.array(...)\n",
    "    try:\n",
    "        word_vect = ....astype(\"float64\")\n",
    "    except:\n",
    "        print(\"Can not convert tokens into vector\")\n",
    "    return word_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>879280</td>\n",
       "      <td>ac452e6e3f90075f2caa</td>\n",
       "      <td>Whether advances from customers are to be reinstated in the financial statements?</td>\n",
       "      <td>0</td>\n",
       "      <td>[whether, advances, from, customers, are, to, be, reinstated, in, the, financial, statements]</td>\n",
       "      <td>[0.5186033333333332, -0.13801260833333331, 0.12842116666666664, 0.007646316666666669, 0.1298301666666667, 0.05123508333333334, -0.3197645, 0.06565250000000002, -0.2282449358333333, 0.014101916666666672, 0.07965062499999999, 0.09712083333333332, -0.30785416666666665, -0.3374477, 0.41093004166666663, 0.30026533333333333, -0.15976524999999997, -0.3167084166666667, -0.15766999999999998, -0.4158830833333333, 0.3490121666666666, -0.043168416666666674, 0.22670500000000002, -0.057427666666666655, -0.22404183333333336, -1.5995716666666666, -0.1264535, -0.07022583333333333, -0.049743249999999996, -0.17334549999999996, 3.1877383333333333, 0.15537208333333333, -0.05052241666666666, -0.6009883333333333, 0.0558911775, -0.25286434166666666, -0.06775129166666666, 0.03568535000000003, -0.006925999999999988, -0.2971213333333333, -0.11890124999999997, -0.020867016666666672, 0.2635008333333333, 0.40399775, -0.10954252499999999, -0.0022747916666666645, -0.2688467583333334, 0.35912608333333335, -0.03927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43285</td>\n",
       "      <td>087846c595acf81fd460</td>\n",
       "      <td>How can you get help?</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, can, you, get, help]</td>\n",
       "      <td>[0.50689562, 0.06207399999999998, 0.487136, -0.383953, 0.459732, -0.12035970199999999, -0.4634638, 0.09031544, 0.023969200000000003, 0.21075, -0.13800000000000004, 0.749918, -0.15734112000000003, 0.0663314, 0.769273, 0.699592, 0.5450200000000001, -0.023261999999999994, 0.385648, -1.035638, -0.21869600000000006, 0.29524, 0.483744, 0.283692, 0.63719, -1.90828, -0.6042919999999999, -0.13570267600000002, 0.849316, -1.0230380000000001, 3.70082, 0.8496599999999999, -0.6758879999999999, -0.41894600000000004, -0.06844380000000001, 0.1480588, -0.061538, 0.1699916, 0.48609600000000003, -0.5718099999999999, -0.148134, 0.12222060000000001, 0.17663679999999998, 0.583872, 0.29337579999999996, 0.11864199999999996, 0.1536154, -0.006048999999999999, -0.1562098, 0.6003020000000001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740986</td>\n",
       "      <td>911f311c129684b0eb08</td>\n",
       "      <td>How does one succeed as a lecturer in medicine in a medical college in India?</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, does, one, succeed, as, a, lecturer, in, medicine, in, a, medical, college, in, india]</td>\n",
       "      <td>[0.07323666666666664, 0.3282313333333333, -0.3943822, -0.21711979999999997, 0.2847428866666667, 0.17198027266666666, -0.4929190666666667, -0.18478980000000003, 0.09907726666666665, -0.10736793333333333, 0.10679233333333332, 0.0026013333333332897, -0.18472040000000006, -0.2184302, 0.22387013333333336, 0.16753906666666668, -0.06628766000000001, 0.33030198, -0.3624220666666666, 0.15911866666666666, 0.24117533333333332, 0.34109039999999996, 0.005400866666666667, 0.07250313333333333, 0.10356999999999998, -1.870526666666667, -0.31733919999999993, -0.275153092, -0.2740633333333334, 0.009833419999999992, 3.1502200000000005, -0.020586466666666674, -0.2869076666666667, -0.5690243999999999, 0.27210666666666666, 0.074661, 0.00275588666666667, 0.5085130666666668, 0.4063372, -0.0648432, -0.23831393333333334, 0.14536638666666668, -0.12115526666666664, 0.1775306666666667, -0.04480393333333333, 0.3054738, -0.05094600000000002, 0.0033737333333333287, -0.030235133333333334, 0.09301366666666669]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472594</td>\n",
       "      <td>5c8a3fa6a63e7e1b86c8</td>\n",
       "      <td>What is the purpose behind the Yellow wallpaper?</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, is, the, purpose, behind, the, yellow, wallpaper]</td>\n",
       "      <td>[0.20248250000000004, 0.270303875, -0.26049, 0.05795637499999999, 0.5790974999999999, 0.16155825000000001, -0.37070826250000005, -0.41170225000000005, -0.0320700575, -0.257588875, 0.05553784, 0.03484000000000001, -0.29944774999999996, -0.002855874999999994, 0.137555125, 0.08844950000000001, 0.06160750000000002, -0.03844000000000003, -0.23410750000000002, -0.57363875, -0.20429025, -0.138234625, 0.024123250000000006, -0.07603412500000001, 0.04394124999999997, -1.3946162500000003, -0.5790506250000002, 0.5142702499999999, 0.3407095, -0.440973, 2.9261475, -0.12308175, -0.39481900000000003, -0.35627749999999997, -0.1483877175, 0.11289235, -0.015213125000000001, 0.17625675000000002, -0.07122885, -0.20517575, 0.086117125, -0.0948227125, -0.12285238750000002, 0.09711437499999998, 0.042062249999999995, 0.10476750000000001, 0.06911347500000001, -0.33918875, 0.15417925, -0.3824299875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453814</td>\n",
       "      <td>58e70e16bd6a778b8e6e</td>\n",
       "      <td>What is the problem by applying under non spp programme for diploma?</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, is, the, problem, by, applying, under, non, spp, programme, for, diploma]</td>\n",
       "      <td>[0.10228499999999996, 0.1616280833333333, -0.2621360833333333, -0.17496466666666666, 0.013830833333333334, 0.27991916666666666, -0.11652300833333334, -0.5318070833333334, 0.06933048083333336, -0.043853333333333334, 0.3777045833333334, 0.16693748333333336, -0.21299074999999998, -0.20035249999999996, 0.40398829166666667, 0.16409150000000003, 0.11596033333333333, 0.27136699999999997, 0.011845000000000017, -0.17380533333333334, 0.16143941666666667, -0.03459016666666666, 0.16009291666666667, -0.06589066666666667, -0.016000583333333315, -1.2845283333333333, -0.15463863333333336, -0.12465575, -0.17625783333333334, 0.0423305, 2.986266666666667, -0.009552916666666684, -0.4953204166666667, -0.3815233333333332, -0.08247433916666663, 0.025679699999999986, 0.22865049999999998, 0.15907983333333334, 0.05586916666666667, -0.03997416666666668, -0.099632, -0.17751914166666669, 0.11900566666666668, 0.14280725000000002, -0.14472025, -0.11361800000000001, -0.10435825833333333, 0.32043916666666666, 0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "879280  ac452e6e3f90075f2caa   \n",
       "43285   087846c595acf81fd460   \n",
       "740986  911f311c129684b0eb08   \n",
       "472594  5c8a3fa6a63e7e1b86c8   \n",
       "453814  58e70e16bd6a778b8e6e   \n",
       "\n",
       "                                                                            question_text  \\\n",
       "879280  Whether advances from customers are to be reinstated in the financial statements?   \n",
       "43285                                                               How can you get help?   \n",
       "740986      How does one succeed as a lecturer in medicine in a medical college in India?   \n",
       "472594                                   What is the purpose behind the Yellow wallpaper?   \n",
       "453814               What is the problem by applying under non spp programme for diploma?   \n",
       "\n",
       "        target  \\\n",
       "879280       0   \n",
       "43285        0   \n",
       "740986       0   \n",
       "472594       0   \n",
       "453814       0   \n",
       "\n",
       "                                                                                               tokens  \\\n",
       "879280  [whether, advances, from, customers, are, to, be, reinstated, in, the, financial, statements]   \n",
       "43285                                                                      [how, can, you, get, help]   \n",
       "740986   [how, does, one, succeed, as, a, lecturer, in, medicine, in, a, medical, college, in, india]   \n",
       "472594                                       [what, is, the, purpose, behind, the, yellow, wallpaper]   \n",
       "453814               [what, is, the, problem, by, applying, under, non, spp, programme, for, diploma]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         vector  \n",
       "879280  [0.5186033333333332, -0.13801260833333331, 0.12842116666666664, 0.007646316666666669, 0.1298301666666667, 0.05123508333333334, -0.3197645, 0.06565250000000002, -0.2282449358333333, 0.014101916666666672, 0.07965062499999999, 0.09712083333333332, -0.30785416666666665, -0.3374477, 0.41093004166666663, 0.30026533333333333, -0.15976524999999997, -0.3167084166666667, -0.15766999999999998, -0.4158830833333333, 0.3490121666666666, -0.043168416666666674, 0.22670500000000002, -0.057427666666666655, -0.22404183333333336, -1.5995716666666666, -0.1264535, -0.07022583333333333, -0.049743249999999996, -0.17334549999999996, 3.1877383333333333, 0.15537208333333333, -0.05052241666666666, -0.6009883333333333, 0.0558911775, -0.25286434166666666, -0.06775129166666666, 0.03568535000000003, -0.006925999999999988, -0.2971213333333333, -0.11890124999999997, -0.020867016666666672, 0.2635008333333333, 0.40399775, -0.10954252499999999, -0.0022747916666666645, -0.2688467583333334, 0.35912608333333335, -0.03927...  \n",
       "43285                                                                                                                                                                                                                                    [0.50689562, 0.06207399999999998, 0.487136, -0.383953, 0.459732, -0.12035970199999999, -0.4634638, 0.09031544, 0.023969200000000003, 0.21075, -0.13800000000000004, 0.749918, -0.15734112000000003, 0.0663314, 0.769273, 0.699592, 0.5450200000000001, -0.023261999999999994, 0.385648, -1.035638, -0.21869600000000006, 0.29524, 0.483744, 0.283692, 0.63719, -1.90828, -0.6042919999999999, -0.13570267600000002, 0.849316, -1.0230380000000001, 3.70082, 0.8496599999999999, -0.6758879999999999, -0.41894600000000004, -0.06844380000000001, 0.1480588, -0.061538, 0.1699916, 0.48609600000000003, -0.5718099999999999, -0.148134, 0.12222060000000001, 0.17663679999999998, 0.583872, 0.29337579999999996, 0.11864199999999996, 0.1536154, -0.006048999999999999, -0.1562098, 0.6003020000000001]  \n",
       "740986           [0.07323666666666664, 0.3282313333333333, -0.3943822, -0.21711979999999997, 0.2847428866666667, 0.17198027266666666, -0.4929190666666667, -0.18478980000000003, 0.09907726666666665, -0.10736793333333333, 0.10679233333333332, 0.0026013333333332897, -0.18472040000000006, -0.2184302, 0.22387013333333336, 0.16753906666666668, -0.06628766000000001, 0.33030198, -0.3624220666666666, 0.15911866666666666, 0.24117533333333332, 0.34109039999999996, 0.005400866666666667, 0.07250313333333333, 0.10356999999999998, -1.870526666666667, -0.31733919999999993, -0.275153092, -0.2740633333333334, 0.009833419999999992, 3.1502200000000005, -0.020586466666666674, -0.2869076666666667, -0.5690243999999999, 0.27210666666666666, 0.074661, 0.00275588666666667, 0.5085130666666668, 0.4063372, -0.0648432, -0.23831393333333334, 0.14536638666666668, -0.12115526666666664, 0.1775306666666667, -0.04480393333333333, 0.3054738, -0.05094600000000002, 0.0033737333333333287, -0.030235133333333334, 0.09301366666666669]  \n",
       "472594                                                                                                                    [0.20248250000000004, 0.270303875, -0.26049, 0.05795637499999999, 0.5790974999999999, 0.16155825000000001, -0.37070826250000005, -0.41170225000000005, -0.0320700575, -0.257588875, 0.05553784, 0.03484000000000001, -0.29944774999999996, -0.002855874999999994, 0.137555125, 0.08844950000000001, 0.06160750000000002, -0.03844000000000003, -0.23410750000000002, -0.57363875, -0.20429025, -0.138234625, 0.024123250000000006, -0.07603412500000001, 0.04394124999999997, -1.3946162500000003, -0.5790506250000002, 0.5142702499999999, 0.3407095, -0.440973, 2.9261475, -0.12308175, -0.39481900000000003, -0.35627749999999997, -0.1483877175, 0.11289235, -0.015213125000000001, 0.17625675000000002, -0.07122885, -0.20517575, 0.086117125, -0.0948227125, -0.12285238750000002, 0.09711437499999998, 0.042062249999999995, 0.10476750000000001, 0.06911347500000001, -0.33918875, 0.15417925, -0.3824299875]  \n",
       "453814  [0.10228499999999996, 0.1616280833333333, -0.2621360833333333, -0.17496466666666666, 0.013830833333333334, 0.27991916666666666, -0.11652300833333334, -0.5318070833333334, 0.06933048083333336, -0.043853333333333334, 0.3777045833333334, 0.16693748333333336, -0.21299074999999998, -0.20035249999999996, 0.40398829166666667, 0.16409150000000003, 0.11596033333333333, 0.27136699999999997, 0.011845000000000017, -0.17380533333333334, 0.16143941666666667, -0.03459016666666666, 0.16009291666666667, -0.06589066666666667, -0.016000583333333315, -1.2845283333333333, -0.15463863333333336, -0.12465575, -0.17625783333333334, 0.0423305, 2.986266666666667, -0.009552916666666684, -0.4953204166666667, -0.3815233333333332, -0.08247433916666663, 0.025679699999999986, 0.22865049999999998, 0.15907983333333334, 0.05586916666666667, -0.03997416666666668, -0.099632, -0.17751914166666669, 0.11900566666666668, 0.14280725000000002, -0.14472025, -0.11361800000000001, -0.10435825833333333, 0.32043916666666666, 0.01...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[\"vector\"] = df_sample[\"tokens\"].apply(lambda x: get_vector_from(x))\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>879280</td>\n",
       "      <td>0.518603</td>\n",
       "      <td>-0.138013</td>\n",
       "      <td>0.128421</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.129830</td>\n",
       "      <td>0.051235</td>\n",
       "      <td>-0.319765</td>\n",
       "      <td>0.065653</td>\n",
       "      <td>-0.228245</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118901</td>\n",
       "      <td>-0.020867</td>\n",
       "      <td>0.263501</td>\n",
       "      <td>0.403998</td>\n",
       "      <td>-0.109543</td>\n",
       "      <td>-0.002275</td>\n",
       "      <td>-0.268847</td>\n",
       "      <td>0.359126</td>\n",
       "      <td>-0.039279</td>\n",
       "      <td>-0.157245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43285</td>\n",
       "      <td>0.506896</td>\n",
       "      <td>0.062074</td>\n",
       "      <td>0.487136</td>\n",
       "      <td>-0.383953</td>\n",
       "      <td>0.459732</td>\n",
       "      <td>-0.120360</td>\n",
       "      <td>-0.463464</td>\n",
       "      <td>0.090315</td>\n",
       "      <td>0.023969</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148134</td>\n",
       "      <td>0.122221</td>\n",
       "      <td>0.176637</td>\n",
       "      <td>0.583872</td>\n",
       "      <td>0.293376</td>\n",
       "      <td>0.118642</td>\n",
       "      <td>0.153615</td>\n",
       "      <td>-0.006049</td>\n",
       "      <td>-0.156210</td>\n",
       "      <td>0.600302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740986</td>\n",
       "      <td>0.073237</td>\n",
       "      <td>0.328231</td>\n",
       "      <td>-0.394382</td>\n",
       "      <td>-0.217120</td>\n",
       "      <td>0.284743</td>\n",
       "      <td>0.171980</td>\n",
       "      <td>-0.492919</td>\n",
       "      <td>-0.184790</td>\n",
       "      <td>0.099077</td>\n",
       "      <td>-0.107368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238314</td>\n",
       "      <td>0.145366</td>\n",
       "      <td>-0.121155</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>-0.044804</td>\n",
       "      <td>0.305474</td>\n",
       "      <td>-0.050946</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>-0.030235</td>\n",
       "      <td>0.093014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472594</td>\n",
       "      <td>0.202483</td>\n",
       "      <td>0.270304</td>\n",
       "      <td>-0.260490</td>\n",
       "      <td>0.057956</td>\n",
       "      <td>0.579097</td>\n",
       "      <td>0.161558</td>\n",
       "      <td>-0.370708</td>\n",
       "      <td>-0.411702</td>\n",
       "      <td>-0.032070</td>\n",
       "      <td>-0.257589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086117</td>\n",
       "      <td>-0.094823</td>\n",
       "      <td>-0.122852</td>\n",
       "      <td>0.097114</td>\n",
       "      <td>0.042062</td>\n",
       "      <td>0.104768</td>\n",
       "      <td>0.069113</td>\n",
       "      <td>-0.339189</td>\n",
       "      <td>0.154179</td>\n",
       "      <td>-0.382430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453814</td>\n",
       "      <td>0.102285</td>\n",
       "      <td>0.161628</td>\n",
       "      <td>-0.262136</td>\n",
       "      <td>-0.174965</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.279919</td>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.531807</td>\n",
       "      <td>0.069330</td>\n",
       "      <td>-0.043853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099632</td>\n",
       "      <td>-0.177519</td>\n",
       "      <td>0.119006</td>\n",
       "      <td>0.142807</td>\n",
       "      <td>-0.144720</td>\n",
       "      <td>-0.113618</td>\n",
       "      <td>-0.104358</td>\n",
       "      <td>0.320439</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>-0.027357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "879280  0.518603 -0.138013  0.128421  0.007646  0.129830  0.051235 -0.319765   \n",
       "43285   0.506896  0.062074  0.487136 -0.383953  0.459732 -0.120360 -0.463464   \n",
       "740986  0.073237  0.328231 -0.394382 -0.217120  0.284743  0.171980 -0.492919   \n",
       "472594  0.202483  0.270304 -0.260490  0.057956  0.579097  0.161558 -0.370708   \n",
       "453814  0.102285  0.161628 -0.262136 -0.174965  0.013831  0.279919 -0.116523   \n",
       "\n",
       "              7         8         9   ...        40        41        42  \\\n",
       "879280  0.065653 -0.228245  0.014102  ... -0.118901 -0.020867  0.263501   \n",
       "43285   0.090315  0.023969  0.210750  ... -0.148134  0.122221  0.176637   \n",
       "740986 -0.184790  0.099077 -0.107368  ... -0.238314  0.145366 -0.121155   \n",
       "472594 -0.411702 -0.032070 -0.257589  ...  0.086117 -0.094823 -0.122852   \n",
       "453814 -0.531807  0.069330 -0.043853  ... -0.099632 -0.177519  0.119006   \n",
       "\n",
       "              43        44        45        46        47        48        49  \n",
       "879280  0.403998 -0.109543 -0.002275 -0.268847  0.359126 -0.039279 -0.157245  \n",
       "43285   0.583872  0.293376  0.118642  0.153615 -0.006049 -0.156210  0.600302  \n",
       "740986  0.177531 -0.044804  0.305474 -0.050946  0.003374 -0.030235  0.093014  \n",
       "472594  0.097114  0.042062  0.104768  0.069113 -0.339189  0.154179 -0.382430  \n",
       "453814  0.142807 -0.144720 -0.113618 -0.104358  0.320439  0.010098 -0.027357  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_sample.vector.apply(lambda x : pd.Series(x))\n",
    "X = X.set_index(df_sample.index)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879280    0\n",
       "43285     0\n",
       "740986    0\n",
       "472594    0\n",
       "453814    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_sample.target\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([X, y], axis=1)\n",
    "df_new = df_new.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_new.target\n",
    "X = df_new.drop(\"target\", axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# TODO: Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1885\n",
      "           1       0.46      0.10      0.17       115\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.70      0.55      0.57      2000\n",
      "weighted avg       0.92      0.94      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO Estimate the accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can you explain why the performance for class 1 (insincere questions) is bad? Can we improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
